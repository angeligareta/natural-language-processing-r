getwd()
# The openNLPmodels.en library is not in CRAN; it has to be installed from another repository
install.packages("openNLPmodels.en", repos = "http://datacube.wu.ac.at")
## Load corpus ----
source_pos = DirSource("./dataset/pos", encoding = "UTF-8")
# Needed for OutOfMemoryError: Java heap space
library(rJava)
install.packages(rJava)
install.packages("rJava")
# Needed for OutOfMemoryError: Java heap space
# install.packages(rJava)
library(rJava)
.jinit(parameters="-Xmx4g")
# Needed for OutOfMemoryError: Java heap space
# install.packages(rJava)
library(rJava).jinit(parameters="-Xmx4g")
library(NLP)
# Needed for OutOfMemoryError: Java heap space
# install.packages("rJava")
# install.packages("openNLPmodels.en", repos = "http://datacube.wu.ac.at")
install.packages("NLP")
install.packages("openNLP")
install.packages("tm")
library(rJava)
.jinit(parameters="-Xmx4g")
library(NLP)
library(openNLP)
library(openNLPmodels.en)
library(tm)
## Utils ----
get_annotations_from_document = function(doc){
x=as.String(doc)
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator <- Maxent_POS_Tag_Annotator()
y1 <- annotate(x, list(sent_token_annotator, word_token_annotator))
y2 <- annotate(x, pos_tag_annotator, y1)
parse_annotator <- Parse_Annotator()
y3 <- annotate(x, parse_annotator, y2)
return(y3)
}
get_annotated_merged_document = function(doc,annotations){
x=as.String(doc)
y2w <- subset(annotations, type == "word")
tags <- sapply(y2w$features, '[[', "POS")
r1 <- sprintf("%s/%s", x[y2w], tags)
r2 <- paste(r1, collapse = " ")
return(r2)
}
get_annotated_plain_text_document = function(doc,annotations){
x=as.String(doc)
a = AnnotatedPlainTextDocument(x,annotations)
return(a)
}
## Load corpus ----
source_pos = DirSource("./dataset/pos", encoding = "UTF-8")
corpus = Corpus(source_pos)
inspect(corpus[[1]])
# install.packages("rJava")
# install.packages("openNLPmodels.en", repos = "http://datacube.wu.ac.at")
#install.packages("NLP")
#install.packages("openNLP")
#install.packages("tm")
library(rJava)
.jinit(parameters="-Xmx4g")
library(NLP)
library(openNLP)
library(openNLPmodels.en)
library(tm)
get_annotations_from_document = function(doc){
x=as.String(doc)
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator <- Maxent_POS_Tag_Annotator()
y1 <- annotate(x, list(sent_token_annotator, word_token_annotator))
y2 <- annotate(x, pos_tag_annotator, y1)
parse_annotator <- Parse_Annotator()
y3 <- annotate(x, parse_annotator, y2)
return(y3)
}
get_annotated_merged_document = function(doc,annotations){
x=as.String(doc)
y2w <- subset(annotations, type == "word")
tags <- sapply(y2w$features, '[[', "POS")
r1 <- sprintf("%s/%s", x[y2w], tags)
r2 <- paste(r1, collapse = " ")
return(r2)
}
get_annotated_plain_text_document = function(doc,annotations){
x=as.String(doc)
a = AnnotatedPlainTextDocument(x,annotations)
return(a)
}
source_pos = DirSource("./dataset/pos", encoding = "UTF-8")
corpus = Corpus(source_pos)
annotations = lapply(corpus, get_annotations_from_document)
